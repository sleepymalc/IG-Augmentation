{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI Dataset: Wine Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import ld\n",
    "from utlis import vectorize_tensor, reconstruct_tensor\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "    cp.random.seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_random_seed(42)\n",
    "k = 5\n",
    "bandwidth = 0.05\n",
    "bandwidth_AE = 0.05\n",
    "eps = np.asarray(1.0e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyDataset(Dataset):\n",
    "    def __init__(self, features, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features (np.ndarray): Feature matrix.\n",
    "            labels (np.ndarray): Label array.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.features[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, label\n",
    "\n",
    "# Normalize transform for UCI dataset\n",
    "class Normalize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = torch.tensor(mean, dtype=torch.float32)\n",
    "        self.std = torch.tensor(std, dtype=torch.float32)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        # std is 0 for constant features, so we add a small epsilon to avoid division by zero\n",
    "        return (sample - self.mean) / (self.std + eps)\n",
    "\n",
    "# Custom transformation for adding Gaussian noise\n",
    "class AddGaussianNoise:\n",
    "    def __init__(self, mean=0.0, std=0.1):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        noise = torch.randn_like(sample) * self.std + self.mean\n",
    "        return sample + noise\n",
    "\n",
    "# Composite transformation to combine Normalize and AddGaussianNoise\n",
    "class CompositeTransform:\n",
    "    def __init__(self, transforms):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            transforms (list): List of transformations to apply in sequence.\n",
    "        \"\"\"\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        for transform in self.transforms:\n",
    "            sample = transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pbb/miniconda3/envs/ig/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "UCI_id = 186 # https://archive.ics.uci.edu/dataset/186/wine-quality\n",
    "test_size = 0.2\n",
    "\n",
    "UCI_dataset = fetch_ucirepo(id=UCI_id)\n",
    "\n",
    "X = np.array(UCI_dataset.data.features)\n",
    "Y = np.array(LabelEncoder().fit_transform(UCI_dataset.data.targets))\n",
    "\n",
    "# normalize to [0, 1]\n",
    "X = (X - X.min()) / (X.max() - X.min())\n",
    "\n",
    "# extend features to 12 dimensions\n",
    "X = np.pad(X, ((0, 0), (0, 12 - X.shape[1])), mode=\"constant\")\n",
    "\n",
    "# Find unique labels\n",
    "unique_labels = np.unique(Y)\n",
    "\n",
    "# Create an array of indices\n",
    "indices = np.arange(len(Y))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Use the shuffled indices to randomly select data for training and testing\n",
    "n_train = int(len(Y) * (1 - test_size))\n",
    "X_train, Y_train = X[indices[:n_train]], Y[indices[:n_train]]\n",
    "X_test, Y_test = X[indices[n_train:]], Y[indices[n_train:]]\n",
    "\n",
    "X_train_class = []\n",
    "Y_train_class = []\n",
    "for i in unique_labels:\n",
    "    X_train_class.append(X_train[np.isin(Y_train, i).flatten()])\n",
    "    Y_train_class.append(Y_train[np.isin(Y_train, i).flatten()])\n",
    "\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "\n",
    "train_dataset = NumpyDataset(X_train, Y_train, transform=Normalize(mean, std))\n",
    "test_dataset = NumpyDataset(X_test, Y_test, transform=Normalize(mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 5197\n",
      "Test size: 1300\n",
      "New sample size: 1036\n",
      "Number of classes: 7\n",
      "Number of features: 11\n"
     ]
    }
   ],
   "source": [
    "D = X_train.shape[1]\n",
    "S = (2, 2, 3)\n",
    "\n",
    "if np.prod(S) != D:\n",
    "    raise ValueError(\"The product of the tensor structure is not equal to the feature dimension\")\n",
    "\n",
    "new_sample_size_per_digit = int(n_train * 0.2 // len(unique_labels))\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Train size: {len(train_dataset)}\")\n",
    "print(f\"Test size: {len(test_dataset)}\")\n",
    "print(f\"New sample size: {new_sample_size_per_digit * len(unique_labels)}\")\n",
    "print(f\"Number of classes: {len(unique_labels)}\")\n",
    "print(f\"Number of features: {D-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo-Non-Linear Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legendre Decomposition (Many-Body Approximation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of Base Sub-Manifold: 10\n"
     ]
    }
   ],
   "source": [
    "B_LD = ld.default_B(S, 2, cp.get_array_module(X_train[0]))\n",
    "print(f\"Dimension of Base Sub-Manifold: {B_LD.shape[0]}\")\n",
    "\n",
    "scaleX_class = []\n",
    "theta_class = []\n",
    "\n",
    "def LD_helper(i, class_):\n",
    "    _, _, scaleX, _, theta = ld.LD(X_train_class[class_][i].reshape(*S), B=B_LD, verbose=False, n_iter=1000, lr=1e-1)\n",
    "    return (scaleX, theta)\n",
    "\n",
    "results = Parallel(n_jobs=30)(delayed(LD_helper)(i, class_) for class_ in unique_labels for i in range(len(X_train_class[class_])))\n",
    "\n",
    "len_class = 0\n",
    "for class_ in unique_labels:\n",
    "    scaleX_list = []\n",
    "    theta_list = []\n",
    "\n",
    "    for i in range(len(X_train_class[class_])):\n",
    "        result = results[i + len_class]\n",
    "\n",
    "        scaleX_list.append(result[0])\n",
    "        theta_list.append(result[1])\n",
    "\n",
    "    len_class += len(X_train_class[class_])\n",
    "\n",
    "    scaleX_class.append(scaleX_list)\n",
    "    theta_class.append(theta_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting on Projected Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_theta_class = []\n",
    "\n",
    "for class_ in unique_labels:\n",
    "    reduced_theta = vectorize_tensor(np.array(theta_class[class_]), B_LD)\n",
    "\n",
    "    # Fit a KDE to the theta values\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth).fit(reduced_theta)\n",
    "    # Sample new data from the KDE\n",
    "    sampled_reduced_theta = kde.sample(n_samples=new_sample_size_per_digit)\n",
    "\n",
    "    sampled_theta = reconstruct_tensor(sampled_reduced_theta, (new_sample_size_per_digit, *S), B_LD)\n",
    "\n",
    "    sampled_theta_class.append(sampled_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Local Data Sub-Manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of Local Data Sub-Manifold: 7\n"
     ]
    }
   ],
   "source": [
    "# Construct the constrained coordinates\n",
    "B_BP = ld.default_B(S, 1, cp.get_array_module(X_train[0]))\n",
    "print(f\"Dimension of Local Data Sub-Manifold: {D - B_BP.shape[0]}\")\n",
    "\n",
    "# Compute every datapoint's eta_hat (served as the linear constraints)\n",
    "eta_hat_class = []\n",
    "\n",
    "for class_ in unique_labels:\n",
    "    eta_hat_list = []\n",
    "    for i in range(X_train_class[class_].shape[0]):\n",
    "        xp = cp.get_array_module(X_train_class[class_][i])\n",
    "        P = (X_train_class[class_][i].reshape(*S) + eps) / scaleX_class[class_][i]\n",
    "        eta_hat = ld.get_eta(P, len(S), xp)\n",
    "        eta_hat_list.append(eta_hat)\n",
    "    eta_hat_list = cp.asarray(eta_hat_list)\n",
    "\n",
    "    eta_hat_class.append(eta_hat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n"
     ]
    }
   ],
   "source": [
    "def BP_helper(i, class_):\n",
    "    N = ld.kNN(sampled_theta_class[class_][i], np.array(theta_class[class_]), k=k)\n",
    "    avg_scale = np.mean(np.array(scaleX_class[class_])[N])\n",
    "    avg_eta_hat = np.mean(eta_hat_class[class_][N], axis=0)\n",
    "\n",
    "    _, _, P, theta = ld.BP(sampled_theta_class[class_][i], [(X_train_class[class_][j].reshape(*S) + eps) / scaleX_class[class_][j] for j in N], avg_eta_hat, avg_scale, B=B_BP, verbose=False, n_iter=1000, lr=5e-2, exit_abs=True)\n",
    "    X_recons_ = P.reshape(-1)\n",
    "    return (theta, X_recons_)\n",
    "\n",
    "results = Parallel(n_jobs=30)(delayed(BP_helper)(i, class_) for i in range(new_sample_size_per_digit) for class_ in unique_labels)\n",
    "\n",
    "sampled_theta_BP_class = []\n",
    "sampled_X_BP_class = []\n",
    "\n",
    "for class_ in unique_labels:\n",
    "    sampled_theta_BP = []\n",
    "    sampled_X_BP = []\n",
    "    for i in range(new_sample_size_per_digit):\n",
    "        result = results[i + new_sample_size_per_digit * class_]\n",
    "\n",
    "        sampled_theta_BP.append(result[0])\n",
    "        sampled_X_BP.append(result[1])\n",
    "\n",
    "    sampled_theta_BP_class.append(np.array(sampled_theta_BP))\n",
    "    sampled_X_BP_class.append(np.array(sampled_X_BP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation with Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size=D, hidden_size=B_LD.shape[0], z_dim=3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, z_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self , x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size=D, hidden_size=B_LD.shape[0], z_dim=3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(z_dim , hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self , x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_original = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "enc = Encoder().to(device)\n",
    "dec = Decoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer_enc = torch.optim.Adam(enc.parameters())\n",
    "optimizer_dec = torch.optim.Adam(dec.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:08<00:00,  1.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3df8f64b90>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = []\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_epoch_loss = 0\n",
    "    for (x , _) in train_loader_original:\n",
    "        x = x.to(device)\n",
    "        x = x.flatten(1)\n",
    "        latents = enc(x)\n",
    "        output = dec(latents)\n",
    "        loss = loss_fn(output , x)\n",
    "        train_epoch_loss += loss.cpu().detach().numpy()\n",
    "        optimizer_enc.zero_grad()\n",
    "        optimizer_dec.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_enc.step()\n",
    "        optimizer_dec.step()\n",
    "    train_loss.append(train_epoch_loss)\n",
    "plt.plot(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "representation = None\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (xs , labels) in train_loader_original:\n",
    "        xs = xs.to(device)\n",
    "        xs = xs.flatten(1)\n",
    "        all_labels.extend(list(labels.numpy()))\n",
    "        latents = enc(xs)\n",
    "        if representation is None:\n",
    "            representation = latents.cpu()\n",
    "        else:\n",
    "            representation = torch.vstack([representation , latents.cpu()])\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "representation = representation.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_X_AE_class = []\n",
    "\n",
    "for class_ in unique_labels:\n",
    "    sampled_X_AE_list = []\n",
    "\n",
    "    rep = representation[np.argwhere(all_labels == class_)].squeeze()\n",
    "    # Fit a KDE to the theta values\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth_AE).fit(rep)\n",
    "\n",
    "    # Sample new data from the KDE\n",
    "    sampled_rep = kde.sample(n_samples=new_sample_size_per_digit)\n",
    "    for i in range(new_sample_size_per_digit):\n",
    "        pred = dec(torch.Tensor(sampled_rep[i])[None , ...].to(device)).cpu().detach().numpy()\n",
    "        sampled_X_AE_list.append(pred.flatten())\n",
    "\n",
    "    sampled_X_AE_class.append(sampled_X_AE_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard loader:\n",
      "Images shape: torch.Size([64, 12]), Labels shape: torch.Size([64])\n",
      "none loader:\n",
      "Images shape: torch.Size([64, 12]), Labels shape: torch.Size([64])\n",
      "PNL_augmented loader:\n",
      "Images shape: torch.Size([64, 12]), Labels shape: torch.Size([64])\n",
      "AE_augmented loader:\n",
      "Images shape: torch.Size([64, 12]), Labels shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Helper function to create a DataLoader for augmented datasets\n",
    "def prepare_augmented_dataset(original_dataset, augmented_data, augmented_labels, transform, batch_size):\n",
    "    # Create dataset from augmented data\n",
    "    augmented_dataset = NumpyDataset(features=augmented_data, labels=augmented_labels, transform=transform)\n",
    "\n",
    "    # Combine with the original dataset\n",
    "    combined_dataset = ConcatDataset([original_dataset, augmented_dataset])\n",
    "\n",
    "    # Create a DataLoader for the combined dataset\n",
    "    return DataLoader(dataset=combined_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Main function to prepare datasets and loaders\n",
    "def create_datasets_and_loaders(batch_size=64):\n",
    "    # Define transformations\n",
    "    transform_standard = CompositeTransform([\n",
    "        Normalize(mean, std),\n",
    "        AddGaussianNoise(mean=0.0, std=std[:-1].min()/4)  # Add Gaussian noise with 1/4 of the standard deviation (omit the last dummy feature)\n",
    "    ])\n",
    "    transform_none = Normalize(mean, std)\n",
    "\n",
    "    train_standard = NumpyDataset(X_train, Y_train, transform=transform_standard)\n",
    "    train_none = NumpyDataset(X_train, Y_train, transform=transform_none)\n",
    "\n",
    "    augmented_data_PNL = []\n",
    "    labels_PNL = []\n",
    "    augmented_data_AE = []\n",
    "    labels_AE = []\n",
    "\n",
    "    for class_ in range(len(unique_labels)):\n",
    "        for data_PNL in sampled_X_BP_class[class_]:\n",
    "            augmented_data_PNL.append(data_PNL)\n",
    "            labels_PNL.append(class_)\n",
    "\n",
    "        for data_AE in sampled_X_AE_class[class_]:\n",
    "            augmented_data_AE.append(data_AE)\n",
    "            labels_AE.append(class_)\n",
    "\n",
    "    augmented_data_PNL = np.array(augmented_data_PNL)\n",
    "    labels_PNL = np.array(labels_PNL)\n",
    "    augmented_data_AE = np.array(augmented_data_AE)\n",
    "    labels_AE = np.array(labels_AE)\n",
    "\n",
    "    mean_LD = augmented_data_PNL.mean(axis=0)\n",
    "    std_LD = augmented_data_PNL.std(axis=0)\n",
    "    transform_none_LD = Normalize(mean_LD, std_LD)\n",
    "\n",
    "    mean_AE = augmented_data_AE.mean(axis=0)\n",
    "    std_AE = augmented_data_AE.std(axis=0)\n",
    "    transform_none_AE = Normalize(mean_AE, std_AE)\n",
    "\n",
    "    # Combine original with augmented data\n",
    "    train_loader_PNL = prepare_augmented_dataset(train_none, augmented_data_PNL, labels_PNL, transform_none_LD, batch_size)\n",
    "    train_loader_AE = prepare_augmented_dataset(train_none, augmented_data_AE, labels_AE, transform_none_AE, batch_size)\n",
    "\n",
    "    # DataLoader for the original dataset only\n",
    "    train_loader_standard = DataLoader(train_standard, batch_size=batch_size, shuffle=True)\n",
    "    train_loader_none = DataLoader(train_none, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return {\n",
    "        \"standard\": train_loader_standard,\n",
    "        \"none\": train_loader_none,\n",
    "        \"PNL_augmented\": train_loader_PNL,\n",
    "        \"AE_augmented\": train_loader_AE,\n",
    "    }\n",
    "\n",
    "loaders = create_datasets_and_loaders(batch_size=64)\n",
    "\n",
    "# Check each DataLoader\n",
    "for name, loader in loaders.items():\n",
    "    print(f\"{name} loader:\")\n",
    "    for images, labels in loader:\n",
    "        print(f\"Images shape: {images.shape}, Labels shape: {labels.shape}\")\n",
    "        break\n",
    "\n",
    "train_loader_standard = loaders[\"standard\"]\n",
    "train_loader_none = loaders[\"none\"]\n",
    "train_loader_PNL = loaders[\"PNL_augmented\"]\n",
    "train_loader_AE = loaders[\"AE_augmented\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=8, num_classes=len(unique_labels)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer = nn.Linear(input_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)  # Flatten the input\n",
    "        x = self.activation(self.hidden_layer(x))  # Apply hidden layer + ReLU\n",
    "        x = self.output_layer(x)  # Apply output layer\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs, device='cuda'):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "def test_model(model, test_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "def bootstrapping(train_loader, test_dataset, num_epochs=10, learning_rate=1e-1, n_bootstrap=20, device='cuda'):\n",
    "    \"\"\"\n",
    "    Train the Logistic Regression model on the training dataset, and evaluate it using bootstrapping on the test dataset.\n",
    "\n",
    "    Args:\n",
    "        train_loader: DataLoader for training data.\n",
    "        test_dataset: Dataset object for the test data.\n",
    "        num_epochs: Number of epochs for training.\n",
    "        learning_rate: Learning rate for the optimizer.\n",
    "        device: Device to run the training on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        Prints the mean accuracy and 95% confidence interval after bootstrapping.\n",
    "    \"\"\"\n",
    "    # Initialize the model, loss, and optimizer\n",
    "    model = MLP(input_size=D ,num_classes=len(unique_labels)).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)  # Decay LR every 30 epochs\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=num_epochs, device=device)\n",
    "\n",
    "    # Perform bootstrapping\n",
    "    accuracies = []\n",
    "\n",
    "    num_test_samples = len(test_dataset) // 2\n",
    "    for i in range(n_bootstrap):\n",
    "        indices = torch.randint(len(test_dataset), size=(num_test_samples,))\n",
    "        bootstrap_subset = Subset(test_dataset, indices)\n",
    "        bootstrap_loader = DataLoader(dataset=bootstrap_subset, batch_size=num_test_samples, shuffle=False)\n",
    "\n",
    "        accuracy = test_model(model, bootstrap_loader, device=device)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    # Compute statistics\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "\n",
    "    print(f\"Mean accuracy: {mean_accuracy:.2f}%\")\n",
    "    print(f\"Standard deviation: {std_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.2273\n",
      "Epoch [2/50], Loss: 1.0999\n",
      "Epoch [3/50], Loss: 1.0840\n",
      "Epoch [4/50], Loss: 1.0702\n",
      "Epoch [5/50], Loss: 1.0739\n",
      "Epoch [6/50], Loss: 1.0713\n",
      "Epoch [7/50], Loss: 1.0714\n",
      "Epoch [8/50], Loss: 1.0704\n",
      "Epoch [9/50], Loss: 1.0686\n",
      "Epoch [10/50], Loss: 1.0616\n",
      "Epoch [11/50], Loss: 1.0707\n",
      "Epoch [12/50], Loss: 1.0627\n",
      "Epoch [13/50], Loss: 1.0640\n",
      "Epoch [14/50], Loss: 1.0636\n",
      "Epoch [15/50], Loss: 1.0579\n",
      "Epoch [16/50], Loss: 1.0639\n",
      "Epoch [17/50], Loss: 1.0556\n",
      "Epoch [18/50], Loss: 1.0565\n",
      "Epoch [19/50], Loss: 1.0567\n",
      "Epoch [20/50], Loss: 1.0639\n",
      "Epoch [21/50], Loss: 1.0622\n",
      "Epoch [22/50], Loss: 1.0703\n",
      "Epoch [23/50], Loss: 1.0556\n",
      "Epoch [24/50], Loss: 1.0529\n",
      "Epoch [25/50], Loss: 1.0581\n",
      "Epoch [26/50], Loss: 1.0561\n",
      "Epoch [27/50], Loss: 1.0565\n",
      "Epoch [28/50], Loss: 1.0538\n",
      "Epoch [29/50], Loss: 1.0610\n",
      "Epoch [30/50], Loss: 1.0605\n",
      "Epoch [31/50], Loss: 1.0296\n",
      "Epoch [32/50], Loss: 1.0184\n",
      "Epoch [33/50], Loss: 1.0223\n",
      "Epoch [34/50], Loss: 1.0179\n",
      "Epoch [35/50], Loss: 1.0225\n",
      "Epoch [36/50], Loss: 1.0160\n",
      "Epoch [37/50], Loss: 1.0180\n",
      "Epoch [38/50], Loss: 1.0207\n",
      "Epoch [39/50], Loss: 1.0166\n",
      "Epoch [40/50], Loss: 1.0178\n",
      "Epoch [41/50], Loss: 1.0197\n",
      "Epoch [42/50], Loss: 1.0169\n",
      "Epoch [43/50], Loss: 1.0148\n",
      "Epoch [44/50], Loss: 1.0146\n",
      "Epoch [45/50], Loss: 1.0123\n",
      "Epoch [46/50], Loss: 1.0158\n",
      "Epoch [47/50], Loss: 1.0136\n",
      "Epoch [48/50], Loss: 1.0139\n",
      "Epoch [49/50], Loss: 1.0154\n",
      "Epoch [50/50], Loss: 1.0134\n",
      "Mean accuracy: 56.90%\n",
      "Standard deviation: 1.55\n"
     ]
    }
   ],
   "source": [
    "bootstrapping(train_loader_none, test_dataset, num_epochs=50, learning_rate=0.1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.2329\n",
      "Epoch [2/50], Loss: 1.1050\n",
      "Epoch [3/50], Loss: 1.0896\n",
      "Epoch [4/50], Loss: 1.0901\n",
      "Epoch [5/50], Loss: 1.0809\n",
      "Epoch [6/50], Loss: 1.0720\n",
      "Epoch [7/50], Loss: 1.0741\n",
      "Epoch [8/50], Loss: 1.0682\n",
      "Epoch [9/50], Loss: 1.0719\n",
      "Epoch [10/50], Loss: 1.0644\n",
      "Epoch [11/50], Loss: 1.0616\n",
      "Epoch [12/50], Loss: 1.0692\n",
      "Epoch [13/50], Loss: 1.0590\n",
      "Epoch [14/50], Loss: 1.0693\n",
      "Epoch [15/50], Loss: 1.0698\n",
      "Epoch [16/50], Loss: 1.0522\n",
      "Epoch [17/50], Loss: 1.0552\n",
      "Epoch [18/50], Loss: 1.0537\n",
      "Epoch [19/50], Loss: 1.0555\n",
      "Epoch [20/50], Loss: 1.0557\n",
      "Epoch [21/50], Loss: 1.0581\n",
      "Epoch [22/50], Loss: 1.0601\n",
      "Epoch [23/50], Loss: 1.0549\n",
      "Epoch [24/50], Loss: 1.0477\n",
      "Epoch [25/50], Loss: 1.0487\n",
      "Epoch [26/50], Loss: 1.0525\n",
      "Epoch [27/50], Loss: 1.0518\n",
      "Epoch [28/50], Loss: 1.0520\n",
      "Epoch [29/50], Loss: 1.0526\n",
      "Epoch [30/50], Loss: 1.0509\n",
      "Epoch [31/50], Loss: 1.0295\n",
      "Epoch [32/50], Loss: 1.0200\n",
      "Epoch [33/50], Loss: 1.0198\n",
      "Epoch [34/50], Loss: 1.0177\n",
      "Epoch [35/50], Loss: 1.0156\n",
      "Epoch [36/50], Loss: 1.0152\n",
      "Epoch [37/50], Loss: 1.0179\n",
      "Epoch [38/50], Loss: 1.0165\n",
      "Epoch [39/50], Loss: 1.0142\n",
      "Epoch [40/50], Loss: 1.0151\n",
      "Epoch [41/50], Loss: 1.0136\n",
      "Epoch [42/50], Loss: 1.0160\n",
      "Epoch [43/50], Loss: 1.0168\n",
      "Epoch [44/50], Loss: 1.0121\n",
      "Epoch [45/50], Loss: 1.0150\n",
      "Epoch [46/50], Loss: 1.0102\n",
      "Epoch [47/50], Loss: 1.0156\n",
      "Epoch [48/50], Loss: 1.0162\n",
      "Epoch [49/50], Loss: 1.0141\n",
      "Epoch [50/50], Loss: 1.0111\n",
      "Mean accuracy: 57.07%\n",
      "Standard deviation: 2.10\n"
     ]
    }
   ],
   "source": [
    "bootstrapping(train_loader_standard, test_dataset, num_epochs=50, learning_rate=0.1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.4651\n",
      "Epoch [2/50], Loss: 1.3870\n",
      "Epoch [3/50], Loss: 1.3758\n",
      "Epoch [4/50], Loss: 1.3548\n",
      "Epoch [5/50], Loss: 1.3365\n",
      "Epoch [6/50], Loss: 1.3395\n",
      "Epoch [7/50], Loss: 1.3345\n",
      "Epoch [8/50], Loss: 1.3333\n",
      "Epoch [9/50], Loss: 1.3311\n",
      "Epoch [10/50], Loss: 1.3297\n",
      "Epoch [11/50], Loss: 1.3233\n",
      "Epoch [12/50], Loss: 1.3297\n",
      "Epoch [13/50], Loss: 1.3231\n",
      "Epoch [14/50], Loss: 1.3237\n",
      "Epoch [15/50], Loss: 1.3132\n",
      "Epoch [16/50], Loss: 1.3221\n",
      "Epoch [17/50], Loss: 1.3213\n",
      "Epoch [18/50], Loss: 1.3220\n",
      "Epoch [19/50], Loss: 1.3164\n",
      "Epoch [20/50], Loss: 1.3253\n",
      "Epoch [21/50], Loss: 1.3186\n",
      "Epoch [22/50], Loss: 1.3196\n",
      "Epoch [23/50], Loss: 1.3152\n",
      "Epoch [24/50], Loss: 1.3112\n",
      "Epoch [25/50], Loss: 1.3143\n",
      "Epoch [26/50], Loss: 1.3184\n",
      "Epoch [27/50], Loss: 1.3111\n",
      "Epoch [28/50], Loss: 1.3108\n",
      "Epoch [29/50], Loss: 1.3185\n",
      "Epoch [30/50], Loss: 1.3165\n",
      "Epoch [31/50], Loss: 1.2881\n",
      "Epoch [32/50], Loss: 1.2777\n",
      "Epoch [33/50], Loss: 1.2754\n",
      "Epoch [34/50], Loss: 1.2721\n",
      "Epoch [35/50], Loss: 1.2729\n",
      "Epoch [36/50], Loss: 1.2722\n",
      "Epoch [37/50], Loss: 1.2715\n",
      "Epoch [38/50], Loss: 1.2708\n",
      "Epoch [39/50], Loss: 1.2691\n",
      "Epoch [40/50], Loss: 1.2715\n",
      "Epoch [41/50], Loss: 1.2696\n",
      "Epoch [42/50], Loss: 1.2695\n",
      "Epoch [43/50], Loss: 1.2703\n",
      "Epoch [44/50], Loss: 1.2712\n",
      "Epoch [45/50], Loss: 1.2692\n",
      "Epoch [46/50], Loss: 1.2686\n",
      "Epoch [47/50], Loss: 1.2690\n",
      "Epoch [48/50], Loss: 1.2716\n",
      "Epoch [49/50], Loss: 1.2693\n",
      "Epoch [50/50], Loss: 1.2694\n",
      "Mean accuracy: 58.12%\n",
      "Standard deviation: 2.05\n"
     ]
    }
   ],
   "source": [
    "bootstrapping(train_loader_PNL, test_dataset, num_epochs=50, learning_rate=0.1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.4360\n",
      "Epoch [2/50], Loss: 1.3269\n",
      "Epoch [3/50], Loss: 1.3015\n",
      "Epoch [4/50], Loss: 1.2860\n",
      "Epoch [5/50], Loss: 1.2620\n",
      "Epoch [6/50], Loss: 1.2439\n",
      "Epoch [7/50], Loss: 1.2238\n",
      "Epoch [8/50], Loss: 1.2268\n",
      "Epoch [9/50], Loss: 1.2034\n",
      "Epoch [10/50], Loss: 1.1910\n",
      "Epoch [11/50], Loss: 1.1946\n",
      "Epoch [12/50], Loss: 1.1871\n",
      "Epoch [13/50], Loss: 1.1944\n",
      "Epoch [14/50], Loss: 1.1750\n",
      "Epoch [15/50], Loss: 1.1745\n",
      "Epoch [16/50], Loss: 1.1723\n",
      "Epoch [17/50], Loss: 1.1717\n",
      "Epoch [18/50], Loss: 1.1723\n",
      "Epoch [19/50], Loss: 1.1782\n",
      "Epoch [20/50], Loss: 1.1672\n",
      "Epoch [21/50], Loss: 1.1752\n",
      "Epoch [22/50], Loss: 1.1779\n",
      "Epoch [23/50], Loss: 1.1713\n",
      "Epoch [24/50], Loss: 1.1686\n",
      "Epoch [25/50], Loss: 1.1718\n",
      "Epoch [26/50], Loss: 1.1701\n",
      "Epoch [27/50], Loss: 1.1693\n",
      "Epoch [28/50], Loss: 1.1599\n",
      "Epoch [29/50], Loss: 1.1761\n",
      "Epoch [30/50], Loss: 1.1590\n",
      "Epoch [31/50], Loss: 1.1325\n",
      "Epoch [32/50], Loss: 1.1243\n",
      "Epoch [33/50], Loss: 1.1220\n",
      "Epoch [34/50], Loss: 1.1208\n",
      "Epoch [35/50], Loss: 1.1197\n",
      "Epoch [36/50], Loss: 1.1213\n",
      "Epoch [37/50], Loss: 1.1216\n",
      "Epoch [38/50], Loss: 1.1206\n",
      "Epoch [39/50], Loss: 1.1207\n",
      "Epoch [40/50], Loss: 1.1221\n",
      "Epoch [41/50], Loss: 1.1202\n",
      "Epoch [42/50], Loss: 1.1196\n",
      "Epoch [43/50], Loss: 1.1181\n",
      "Epoch [44/50], Loss: 1.1176\n",
      "Epoch [45/50], Loss: 1.1185\n",
      "Epoch [46/50], Loss: 1.1197\n",
      "Epoch [47/50], Loss: 1.1186\n",
      "Epoch [48/50], Loss: 1.1195\n",
      "Epoch [49/50], Loss: 1.1190\n",
      "Epoch [50/50], Loss: 1.1191\n",
      "Mean accuracy: 56.61%\n",
      "Standard deviation: 1.84\n"
     ]
    }
   ],
   "source": [
    "bootstrapping(train_loader_AE, test_dataset, num_epochs=50, learning_rate=0.1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
