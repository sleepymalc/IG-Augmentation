{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI Dataset: Log-Linear Model v.s. Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "import ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_factorization(D):\n",
    "    factors = []\n",
    "\n",
    "    # Try to find a factorization with 3 factors first\n",
    "    for a in range(2, int(D**(1/3)) + 2):\n",
    "        if D % a == 0:\n",
    "            bc = D // a\n",
    "            for b in range(a, int(bc**(1/2)) + 2):\n",
    "                if bc % b == 0:\n",
    "                    c = bc // b\n",
    "                    factors.append((a, b, c))\n",
    "                    return factors\n",
    "\n",
    "    # If 3-factor factorization is not found, try 2-factor factorization\n",
    "    for a in range(2, int(D**(1/2)) + 2):\n",
    "        if D % a == 0:\n",
    "            b = D // a\n",
    "            factors.append((a, b))\n",
    "            return factors\n",
    "\n",
    "    return factors\n",
    "\n",
    "def vectorize_tensor(T, B):\n",
    "    \"\"\"\n",
    "    Vectorizes the tensor T by selecting only the indices in B.\n",
    "\n",
    "    Parameters:\n",
    "    - T: numpy array of shape (num_samples, ...)\n",
    "    - B: list of indices to select from each sample\n",
    "\n",
    "    Returns:\n",
    "    - V: vectorized representation of T of shape (num_samples, len(B))\n",
    "    \"\"\"\n",
    "    num_samples = T.shape[0]\n",
    "    V = np.zeros((num_samples, len(B)))\n",
    "    for i in range(num_samples):\n",
    "        for j, idx in enumerate(B):\n",
    "            V[i, j] = T[i, *idx]\n",
    "    return V\n",
    "\n",
    "def reconstruct_tensor(V, T_shape, B):\n",
    "    \"\"\"\n",
    "    Reconstructs the tensor T from its vectorized representation V.\n",
    "\n",
    "    Parameters:\n",
    "    - V: vectorized representation of T of shape (num_samples, len(B))\n",
    "    - T_shape: original shape of the tensor T\n",
    "    - B: list of indices that were used to create the vectorized representation\n",
    "\n",
    "    Returns:\n",
    "    - T: reconstructed tensor with the original shape, missing values filled with zero\n",
    "    \"\"\"\n",
    "    num_samples = V.shape[0]\n",
    "    T = np.zeros(T_shape)\n",
    "    for i in range(num_samples):\n",
    "        for j, idx in enumerate(B):\n",
    "            T[i, *idx] = V[i, j]\n",
    "    return T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCI_id = 464"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features: (21263, 81)\n",
      "Shape of labels: (21263, 1)\n"
     ]
    }
   ],
   "source": [
    "UCI_dataset = fetch_ucirepo(id=UCI_id)\n",
    "\n",
    "X = np.array(UCI_dataset.data.features)\n",
    "Y = np.array(UCI_dataset.data.targets)\n",
    "\n",
    "# Print the shape of features and labels\n",
    "print(\"Shape of features:\", X.shape)\n",
    "print(\"Shape of labels:\", Y.shape)\n",
    "\n",
    "# Normalize the input data\n",
    "# X_mean = np.mean(X, axis=0)\n",
    "# X_std = np.std(X, axis=0)\n",
    "# X = normalization(X, X_mean, X_std)\n",
    "\n",
    "# Create an array of indices\n",
    "indices = np.arange(len(Y))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Use the shuffled indices to randomly select data for training and testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 22590.0\n",
      "0.00021 185.0\n"
     ]
    }
   ],
   "source": [
    "print(X.min(), X.max())\n",
    "print(Y.min(), Y.max())\n",
    "\n",
    "# Stacking the features and labels together\n",
    "# X = np.hstack((X_train, Y_train.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Structure of the Feature: (3, 3, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "# Feature dimension\n",
    "D = X_train.shape[1]\n",
    "S = find_factorization(D)[0]\n",
    "S = (3, 3, 3, 3)\n",
    "print(\"Tensor Structure of the Feature:\", S)\n",
    "X = [np.asarray(x).reshape(S) for x in X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legendre Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_LD = ld.default_B(S, 2, cp.get_array_module(X[0]))\n",
    "# B_LD = step_B(S, (1, 2, 2))\n",
    "\n",
    "scaleX_list = []\n",
    "theta_list = []\n",
    "\n",
    "def helper(x):\n",
    "    _, _, scaleX, _, theta = ld.LD(x, B=B_LD, verbose=False, n_iter=1000, lr=1e-1)\n",
    "    return (scaleX, theta)\n",
    "\n",
    "results = Parallel(n_jobs=30)(delayed(helper)(x) for x in X)\n",
    "\n",
    "for i in range(len(results)):\n",
    "    scaleX_list.append(results[i][0])\n",
    "    theta_list.append(results[i][1])\n",
    "\n",
    "scaleX_list = np.array(scaleX_list)\n",
    "theta_list = np.array(theta_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "num_new_samples = 160\n",
    "\n",
    "reduced_theta = vectorize_tensor(np.array(theta_list), B_LD)\n",
    "\n",
    "# Fit a KDE to the theta values\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.05).fit(reduced_theta)\n",
    "# Sample new data from the KDE\n",
    "sampled_reduced_theta = kde.sample(n_samples=num_new_samples)\n",
    "\n",
    "sampled_theta_list = reconstruct_tensor(sampled_reduced_theta, (num_new_samples, *S), B_LD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Submanifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "# Construct the constrained coordinates\n",
    "B_BP = ld.default_B(S, 1, cp.get_array_module(X[0]))\n",
    "\n",
    "print(B_BP.shape)\n",
    "\n",
    "# Compute every datapoint's eta_hat (served as the linear constraints)\n",
    "eta_hat_list = []\n",
    "for i in range(len(X)):\n",
    "    x = X[i]\n",
    "    eps = np.asarray(1.0e-5)\n",
    "    xp = cp.get_array_module(x)\n",
    "    eta_hat = ld.get_eta((x + eps) / scaleX_list[i], len(S), xp)\n",
    "    eta_hat_list.append(eta_hat)\n",
    "eta_hat_list = cp.asarray(eta_hat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n",
      "Warning: Not Converged. Consider increasing the number of iterations.\n"
     ]
    }
   ],
   "source": [
    "sampled_P_list_BP = []\n",
    "sampled_theta_list_BP = []\n",
    "X_recons_list = []\n",
    "Y_recons_list = []\n",
    "\n",
    "def helper2(i):\n",
    "    ks = ld.kNN(sampled_theta_list[i], np.array(theta_list), k=10)\n",
    "    Y_recons = np.mean(Y_train[ks])\n",
    "    avg_scale = np.mean(np.array(scaleX_list)[ks], axis=0)\n",
    "    avg_eta_hat = np.mean(eta_hat_list[ks], axis=0)\n",
    "    _, _, P, theta = ld.BP(sampled_theta_list[i], [(X[k] + eps) / scaleX_list[k] for k in ks], avg_eta_hat, avg_scale, B=B_BP, verbose=False, n_iter=1000, lr=5e-2, exit_abs=True)\n",
    "    X_recons = (P).astype(np.int32).reshape(-1)\n",
    "    return (P, theta, X_recons, Y_recons)\n",
    "\n",
    "results = Parallel(n_jobs=30)(delayed(helper2)(i) for i in range(num_new_samples))\n",
    "\n",
    "for i in range(len(results)):\n",
    "    sampled_P_list_BP.append(results[i][0])\n",
    "    sampled_theta_list_BP.append(results[i][1])\n",
    "    X_recons_list.append(results[i][2])\n",
    "    Y_recons_list.append(results[i][3])\n",
    "\n",
    "sampled_P_list_BP = np.array(sampled_P_list_BP)\n",
    "sampled_theta_list_BP = np.array(sampled_theta_list_BP)\n",
    "X_recons_list = np.array(X_recons_list)\n",
    "Y_recons_list = np.array(Y_recons_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 2, 2, 2)\n",
      "(160, 2, 2, 2)\n",
      "(160, 8)\n",
      "(160,)\n"
     ]
    }
   ],
   "source": [
    "print(sampled_P_list_BP.shape)\n",
    "print(sampled_theta_list_BP.shape)\n",
    "print(X_recons_list.shape)\n",
    "print(Y_recons_list.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generated Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 7.75\n",
      "Mean Squared Error (MSE): 95.97\n",
      "Root Mean Squared Error (RMSE): 9.80\n",
      "R-squared (R2): 0.63\n",
      "Accuracy on the test set: 0.6275531792314855\n"
     ]
    }
   ],
   "source": [
    "# Train a linear regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "Y_test_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "mae = mean_absolute_error(Y_test, Y_test_pred)\n",
    "mse = mean_squared_error(Y_test, Y_test_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, Y_test_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n",
    "\n",
    "# Measure the accuracy on the test set\n",
    "accuracy = lr.score(X_test, Y_test)\n",
    "print(\"Accuracy on the test set:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained on Generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 22.35\n",
      "Mean Squared Error (MSE): 604.62\n",
      "Root Mean Squared Error (RMSE): 24.59\n",
      "R-squared (R2): -1.35\n",
      "Accuracy on the test set: -1.3464263251771693\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to numpy arrays\n",
    "# X_train_new = X_recons_list[:, :-1]\n",
    "# print(X_train_new.shape)\n",
    "# Y_train_new = X_recons_list[:, -1]\n",
    "# print(Y_train_new.shape)\n",
    "\n",
    "X_train_new = np.array(X_recons_list)\n",
    "Y_train_new = np.array(Y_recons_list)\n",
    "\n",
    "# Train a linear regression model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_new, Y_train_new)\n",
    "\n",
    "# Predict on the test set\n",
    "Y_test_pred = lr.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "mae = mean_absolute_error(Y_test, Y_test_pred)\n",
    "mse = mean_squared_error(Y_test, Y_test_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(Y_test, Y_test_pred)\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n",
    "\n",
    "# Measure the accuracy on the test set\n",
    "accuracy = lr.score(X_test, Y_test)\n",
    "print(\"Accuracy on the test set:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.8076923076923077\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert lists to numpy arrays\n",
    "X_train_with_new = np.concatenate((X_train, X_train_new))\n",
    "Y_train_with_new = np.concatenate((Y_train, Y_train_new))\n",
    "\n",
    "# Train a logistic classifier\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_with_new, Y_train_with_new)\n",
    "\n",
    "# Measure the accuracy on the test set\n",
    "accuracy = clf.score(X_test, Y_test)\n",
    "print(\"Accuracy on the test set:\", accuracy)\n",
    "\n",
    "# Optional: Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(Y_test, y_pred, labels=unique_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=unique_labels)\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
